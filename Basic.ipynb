{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69fd62e3-c85f-4443-803e-4e8a8cd0d72c",
   "metadata": {},
   "source": [
    "# Dependensies\n",
    "`pip install 'stable-baselines3[extra]'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f712635-ad81-4e95-a267-fb79621e4ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym # simulation environment\n",
    "from stable_baselines3 import PPO # training algorithm\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv # if env.step() is fast, use this\n",
    "# from stable_baselines3.common.vec_env import SubprocVecEnv # if env.step() is slow, use this\n",
    "from stable_baselines3.common.evaluation import evaluate_policy \n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93873806-fff2-40b9-a317-3be41e5a66ff",
   "metadata": {},
   "source": [
    "# Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797510e4-b4a2-461d-9419-c41b8bfa3e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"CartPole-v0\" # specify the environment\n",
    "env_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b5c2c-c18c-4248-b66e-6613113bcfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(env_name) # initialize the entire environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93e113e-af29-4c6d-834b-aa1554152adb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "episodes = 5 # epoch, times of training\n",
    "for episode in range(episodes):\n",
    "    state = env.reset() # initialize the state of environment\n",
    "    done = False # is the environment done or not (e.g. clear the stage or the character is dead)\n",
    "    score = 0 # total reward\n",
    "    \n",
    "    while not done:\n",
    "        env.render() # visualize the environment\n",
    "        action = env.action_space.sample() # random action\n",
    "        state, reward, done, info = env.step(action) # take the action, and obtain the current state\n",
    "        score += reward\n",
    "    print(f'episode: {episode} score: {score}')\n",
    "    env.close() # close the visualize window, but it doesn't work well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4dac34-65bf-4ad6-abf6-581db3094b4c",
   "metadata": {},
   "source": [
    "# What's Environment ?\n",
    "https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py\n",
    "## Types of space\n",
    "- Box: range of values, n dimensional tensor\n",
    "    - Box(0, 1, shape=(2,))\n",
    "    - [0.1, 0.2], [0.25, 0.75], ...\n",
    "- Discrete: set of items\n",
    "    - Discrete(2)\n",
    "    - 0, 1\n",
    "- Tuple: tuple of other spaces\n",
    "    - Tuple((Discrete(2), Box(0, 1, shape=(2,))))\n",
    "    - (0, [0.1, 0.2]), (1, [0.25, 0.75]), ...\n",
    "- ...\n",
    "\n",
    "## Two spaces in environment\n",
    "- action_space\n",
    "- observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc0a79c-e1ea-46bf-8416-274ff3c426e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'action space: {env.action_space}\\nsample: {env.action_space.sample()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0610e9d0-39cb-4868-9f93-8ae033eb12ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'observation space: {env.observation_space}\\nsample: {env.observation_space.sample()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa1ed9c-2f6a-459a-b178-bf0941880a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'return of env.reset: {env.reset()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f480cb0-af69-4a7b-932d-e76e35e75f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'return of env.step: {env.step(1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe4a89-c5eb-4995-9622-82f03b556e5d",
   "metadata": {},
   "source": [
    "# Training RL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a35514-eb7f-4bb7-8f83-754965f50e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(env_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8200f393-daaf-4957-b70a-27e5b46bc579",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps= 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bb0284-61de-4718-baf1-fb203d89c35c",
   "metadata": {},
   "source": [
    "# Save and reload the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ee26d-a9e5-43e7-a5e8-67afe234b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = os.path.join('training', 'saved_model', 'PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950cc2ca-6c79-4d7f-8c49-bac3942cf547",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c62a67-a6bc-4da4-8cdd-e362b8efc833",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3d587e-71c8-40c8-90f9-9559e0589282",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(model_save_path, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff14f0e1-461e-4de1-9cc2-b046fd1d533c",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad9ce53-ae80-49fe-9752-d10785f6b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes= 5, render= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d4c0e-e248-483f-85d8-4f797debaf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febb5cfc-d377-46b2-9452-e5f1bec6eb34",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289b3ef0-ab86-470f-aace-5af2ebcec4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 5\n",
    "for episode in range(episodes):\n",
    "    state = env.reset() # initialize the observation (including state) of environment\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _ = model.predict(state) # based on current state, predict the action\n",
    "        observation = env.step(action) # take the action\n",
    "        state, reward, done, info = observation # observation includes state, reward, done, info\n",
    "        score += reward\n",
    "    print(f'episode: {episode} score: {score}')\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e335072-9f9f-4eef-bd84-29e4b132f428",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95a094-2e5a-42c3-a29b-95ad7b83da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_save_path = os.path.join('training', 'log')\n",
    "log_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a816ad-87ef-4204-a23e-1d8c6bd5526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"CartPole-v0\"\n",
    "env = gym.make(env_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose= 1, tensorboard_log= log_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd0f6ef-6f1a-4455-920b-f27a13cf0cec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps= 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d10e94-80e5-48ce-a2c2-0017c028ec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir={log_save_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e27f1-2ded-4ff1-8079-b4c38614e2d8",
   "metadata": {},
   "source": [
    "# Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d27034-e2c4-4ee2-934c-941537a254df",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold= 190, verbose= 1)\n",
    "eval_callback = EvalCallback(env, \n",
    "                             callback_on_new_best= stop_callback, # when there is a better model, call stop_callback\n",
    "                             eval_freq= 10000, # evaluate every 10000 episodes\n",
    "                             best_model_save_path= model_save_path,\n",
    "                             verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fae090-56ce-4719-926c-7947bdbe3c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"CartPole-v0\"\n",
    "env = gym.make(env_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa701c5-22f7-43b3-9abd-a5a47c2fa6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps= 20000, callback= eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156b7599-be0b-4041-9992-e5b5ced76d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "best_model_save_path = os.path.join(model_save_path, 'best_model')\n",
    "model = PPO.load(best_model_save_path, env= env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581c9ddc-b497-4995-baa3-676a7f7fe607",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes= 10, render= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bade8a-54a7-42ed-b290-3e17d2476a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
